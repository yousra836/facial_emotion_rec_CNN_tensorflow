{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c27597a6",
   "metadata": {},
   "source": [
    "# importing all libs needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc320fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa4676f",
   "metadata": {},
   "source": [
    "# Load csv files and add pixels to X and labels to y Load csv files and add pixels to X and labels to y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbe6a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_rows', 500)\n",
    "# pd.set_option('display.max_columns', 500)\n",
    "# pd.set_option('display.width', 1000)\n",
    "\n",
    "df=pd.read_csv('fer2013.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d2145c",
   "metadata": {},
   "source": [
    "# some informations about data in the .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bd46a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35887 entries, 0 to 35886\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   emotion  35887 non-null  int64 \n",
      " 1   pixels   35887 non-null  object\n",
      " 2   Usage    35887 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 841.2+ KB\n",
      "None\n",
      "Training       28709\n",
      "PublicTest      3589\n",
      "PrivateTest     3589\n",
      "Name: Usage, dtype: int64\n",
      "   emotion                                             pixels     Usage\n",
      "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
      "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
      "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
      "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
      "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training\n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "print(df[\"Usage\"].value_counts())\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8fc0a7",
   "metadata": {},
   "source": [
    "# array that contain y_tain in test_y as label : emotions and the x_train in the x_test as value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70374e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,train_y,X_test,test_y=[],[],[],[]\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    val=row['pixels'].split(\" \")\n",
    "    try:\n",
    "        if 'Training' in row['Usage']:\n",
    "            X_train.append(np.array(val,'float32'))\n",
    "            train_y.append(row['emotion'])\n",
    "        elif 'PublicTest' in row['Usage']:\n",
    "            X_test.append(np.array(val,'float32'))\n",
    "            test_y.append(row['emotion'])\n",
    "    except:\n",
    "        print(f\"error occured at index :{index} and row:{row}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa457159",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 64\n",
    "num_labels = 7\n",
    "batch_size = 64\n",
    "width, height = 48, 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03e235c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train,'float32')\n",
    "train_y = np.array(train_y,'float32')\n",
    "X_test = np.array(X_test,'float32')\n",
    "test_y = np.array(test_y,'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "906ad5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y=np_utils.to_categorical(train_y, num_classes=num_labels)\n",
    "test_y=np_utils.to_categorical(test_y, num_classes=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5be6522",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can t produce\n",
    "#normalize data from 0 to 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee1b44b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train -= np.mean(X_train, axis=0)\n",
    "X_train /= np.std(X_train, axis=0)\n",
    "\n",
    "X_test -= np.mean(X_test, axis=0)\n",
    "X_test /= np.std(X_test, axis=0)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce641b6",
   "metadata": {},
   "source": [
    "# we build the cnn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b65a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "### 1st 2D convolution layer (la convolution spatiale sur les images).\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(X_train.shape[1:])))\n",
    "model.add(Conv2D(64,kernel_size= (3, 3), activation='relu'))\n",
    "\n",
    "\n",
    "#### model.add(BatchNormalization())\n",
    "#the pooling layer\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "### 2nd 2D convolution layer \n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "#### model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "### 3th 2D convolution layer \n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "#the pooling layer\n",
    "#### model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "### fully connected layer ( FC)\n",
    "\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "#add costumed layer\n",
    "model.add(Dense(num_labels, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc37dde0",
   "metadata": {},
   "source": [
    "# Compliling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54138fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b7dd1f",
   "metadata": {},
   "source": [
    "# Training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a7f349f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "449/449 [==============================] - 744s 2s/step - loss: 1.7100 - accuracy: 0.3016 - val_loss: 1.5300 - val_accuracy: 0.3904\n",
      "Epoch 2/25\n",
      "449/449 [==============================] - 893s 2s/step - loss: 1.4982 - accuracy: 0.4138 - val_loss: 1.4332 - val_accuracy: 0.4299\n",
      "Epoch 3/25\n",
      "449/449 [==============================] - 1025s 2s/step - loss: 1.3973 - accuracy: 0.4548 - val_loss: 1.3010 - val_accuracy: 0.5021\n",
      "Epoch 4/25\n",
      "449/449 [==============================] - 941s 2s/step - loss: 1.3351 - accuracy: 0.4824 - val_loss: 1.2692 - val_accuracy: 0.5191\n",
      "Epoch 5/25\n",
      "449/449 [==============================] - 948s 2s/step - loss: 1.2920 - accuracy: 0.5019 - val_loss: 1.2559 - val_accuracy: 0.5160\n",
      "Epoch 6/25\n",
      "449/449 [==============================] - 851s 2s/step - loss: 1.2537 - accuracy: 0.5190 - val_loss: 1.2134 - val_accuracy: 0.5316\n",
      "Epoch 7/25\n",
      "449/449 [==============================] - 770s 2s/step - loss: 1.2298 - accuracy: 0.5254 - val_loss: 1.2140 - val_accuracy: 0.5350\n",
      "Epoch 8/25\n",
      "449/449 [==============================] - 765s 2s/step - loss: 1.2030 - accuracy: 0.5422 - val_loss: 1.1890 - val_accuracy: 0.5419\n",
      "Epoch 9/25\n",
      "449/449 [==============================] - 788s 2s/step - loss: 1.1758 - accuracy: 0.5493 - val_loss: 1.1817 - val_accuracy: 0.5483\n",
      "Epoch 10/25\n",
      "449/449 [==============================] - 756s 2s/step - loss: 1.1593 - accuracy: 0.5545 - val_loss: 1.1871 - val_accuracy: 0.5453\n",
      "Epoch 11/25\n",
      "449/449 [==============================] - 755s 2s/step - loss: 1.1355 - accuracy: 0.5644 - val_loss: 1.1558 - val_accuracy: 0.5634\n",
      "Epoch 12/25\n",
      "449/449 [==============================] - 758s 2s/step - loss: 1.1171 - accuracy: 0.5756 - val_loss: 1.1530 - val_accuracy: 0.5606\n",
      "Epoch 13/25\n",
      "449/449 [==============================] - 756s 2s/step - loss: 1.0981 - accuracy: 0.5802 - val_loss: 1.1352 - val_accuracy: 0.5670\n",
      "Epoch 14/25\n",
      "449/449 [==============================] - 41486s 93s/step - loss: 1.0859 - accuracy: 0.5825 - val_loss: 1.1420 - val_accuracy: 0.5642\n",
      "Epoch 15/25\n",
      "449/449 [==============================] - 867s 2s/step - loss: 1.0703 - accuracy: 0.5901 - val_loss: 1.1384 - val_accuracy: 0.5637\n",
      "Epoch 16/25\n",
      "449/449 [==============================] - 1026s 2s/step - loss: 1.0438 - accuracy: 0.5994 - val_loss: 1.1353 - val_accuracy: 0.5698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23501febfa0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "model.fit(X_train, train_y,\n",
    "          callbacks=[es_callback],\n",
    "          batch_size=batch_size,\n",
    "          epochs=25,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, test_y),\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2416af1b",
   "metadata": {},
   "source": [
    "# Saving the  model to  use it later on as json and h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "501fa7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fer_json = model.to_json()\n",
    "with open(\"fer.json\", \"w\") as json_file:\n",
    "    json_file.write(fer_json)\n",
    "model.save_weights(\"fer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d2f73b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4f8ba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1600e64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5be410a",
   "metadata": {},
   "source": [
    "# live cam prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bff6bd8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function destroyAllWindows>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing import image\n",
    "\n",
    "#load model\n",
    "model = model_from_json(open(\"fer.json\", \"r\").read())\n",
    "#load weights\n",
    "model.load_weights('fer.h5')\n",
    "\n",
    "#casscade classifier for the frontal face (opencv2)\n",
    "\n",
    "face_haar_cascade = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # captures frame and returns boolean value and captured image\n",
    "    ret,test_img=cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "    gray_img= cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces_detected = face_haar_cascade.detectMultiScale(gray_img, 1.32, 5)\n",
    "\n",
    "\n",
    "    for (x,y,w,h) in faces_detected:\n",
    "        cv2.rectangle(test_img,(x,y),(x+w,y+h),(255,0,0),thickness=7)\n",
    "        roi_gray=gray_img[y:y+w,x:x+h]#cropping region of interest i.e. face area from  image\n",
    "        roi_gray=cv2.resize(roi_gray,(48,48))\n",
    "        img_pixels = image.img_to_array(roi_gray)\n",
    "        img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "        img_pixels /= 255\n",
    "\n",
    "        predictions = model.predict(img_pixels)\n",
    "\n",
    "        #find max indexed array\n",
    "        max_index = np.argmax(predictions[0])\n",
    "\n",
    "        emotions = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "        predicted_emotion = emotions[max_index]\n",
    "\n",
    "        cv2.putText(test_img, predicted_emotion, (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "\n",
    "    resized_img = cv2.resize(test_img, (1000, 700))\n",
    "    cv2.imshow('Facial emotion analysis ',resized_img)\n",
    "\n",
    "\n",
    "    #wait until 'q' key is pressed to exit\n",
    "    if cv2.waitKey(10) == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43299e01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
